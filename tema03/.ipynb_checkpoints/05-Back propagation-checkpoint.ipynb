{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propagacion hacia atras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de Regresión\n",
    "- $X \\sim N(1.0, 0.1)$\n",
    "- $y = Ax, A = 10$\n",
    "- target = 10\n",
    "- $L2$ función de pérdidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = np.random.normal(loc=1, scale=0.1, size=200)\n",
    "y_vals = np.repeat(10.,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "A = tf.Variable(tf.random_normal(shape=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pred = tf.multiply(A,x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.square(my_pred - y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_optim = tf.train.GradientDescentOptimizer(learning_rate=0.025)\n",
    "train_step = my_optim.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso #20 A = [9.962016] Loss: [1.6658177]\n",
      "Paso #40 A = [10.055169] Loss: [0.0648904]\n",
      "Paso #60 A = [9.975678] Loss: [0.14430153]\n",
      "Paso #80 A = [10.008554] Loss: [1.9741502]\n",
      "Paso #100 A = [9.894084] Loss: [0.7651811]\n",
      "Paso #120 A = [10.112123] Loss: [0.08902828]\n",
      "Paso #140 A = [10.124039] Loss: [4.8080144]\n",
      "Paso #160 A = [9.887412] Loss: [0.00831168]\n",
      "Paso #180 A = [10.221618] Loss: [4.855527]\n",
      "Paso #200 A = [10.283243] Loss: [2.173674]\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    rand_index = np.random.choice(200)\n",
    "    rand_x = [x_vals[rand_index]]\n",
    "    rand_y = [y_vals[rand_index]]\n",
    "    session.run(train_step, feed_dict={x_data : rand_x, y_target : rand_y})\n",
    "    if (i+1)%20==0:\n",
    "        print(\"Paso #\"+str(i+1)+\" A = \"+str(session.run(A)) + \n",
    "              \" Loss: \"+str(session.run(loss, feed_dict={x_data:rand_x, y_target: rand_y})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de clasificación binaria\n",
    "- $X_1\\sim N(-2, 1), X_2 \\sim N(2,1)$\n",
    "- $target(X_1) = 0, target(X_2) = 1$\n",
    "- sigmoid(x+A) = $\\frac{1}{1+e^{-(x+A)}}$\n",
    "- Determinar el valor de $A$\n",
    "- Teóricamente $A\\simeq \\frac{m_1+m_2}{2}, m_1 = -2, m_2 = 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = np.concatenate((np.random.normal(-2,1,100), np.random.normal(2,1,100)))\n",
    "y_vals = np.concatenate((np.repeat(0.,100),np.repeat(1.,100)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "A = tf.Variable(tf.random_normal(mean=10,shape=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tf.add(x_data,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_expanded = tf.expand_dims(pred,0)\n",
    "y_target_expanded = tf.expand_dims(y_target,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.032389]\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "session.run(init)\n",
    "print(session.run(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "xentrop = tf.nn.sigmoid_cross_entropy_with_logits(logits = pred_expanded, labels=y_target_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tf.train.GradientDescentOptimizer(learning_rate=0.03)\n",
    "train_step = optim.minimize(xentrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso #100, A = [8.803626], Loss = [[4.679236]]\n",
      "Paso #200, A = [7.249325], Loss = [[6.7675724]]\n",
      "Paso #300, A = [5.743675], Loss = [[0.00022567]]\n",
      "Paso #400, A = [4.10236], Loss = [[2.3431997]]\n",
      "Paso #500, A = [2.9126313], Loss = [[1.5622361]]\n",
      "Paso #600, A = [2.0328932], Loss = [[0.01426269]]\n",
      "Paso #700, A = [1.438611], Loss = [[0.13344045]]\n",
      "Paso #800, A = [1.087429], Loss = [[0.01746589]]\n",
      "Paso #900, A = [0.8280665], Loss = [[0.25450295]]\n",
      "Paso #1000, A = [0.6157821], Loss = [[0.04290753]]\n",
      "Paso #1100, A = [0.46004796], Loss = [[0.20205463]]\n",
      "Paso #1200, A = [0.3396258], Loss = [[0.5611539]]\n",
      "Paso #1300, A = [0.14809789], Loss = [[0.26865608]]\n",
      "Paso #1400, A = [0.12673336], Loss = [[0.02996251]]\n",
      "Paso #1500, A = [0.14475629], Loss = [[0.08634856]]\n",
      "Paso #1600, A = [0.10859808], Loss = [[0.29081184]]\n",
      "Paso #1700, A = [0.06564821], Loss = [[0.1537654]]\n",
      "Paso #1800, A = [0.11997987], Loss = [[0.27404547]]\n",
      "Paso #1900, A = [0.16472746], Loss = [[0.25884917]]\n",
      "Paso #2000, A = [0.09724952], Loss = [[0.16208903]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2000):\n",
    "    rand_idx = np.random.choice(200)\n",
    "    rand_x = [x_vals[rand_idx]]\n",
    "    rand_y = [y_vals[rand_idx]]\n",
    "    session.run(train_step, feed_dict={x_data:rand_x, y_target:rand_y})\n",
    "    if (i+1)%100==0:\n",
    "        print(\"Paso #\"+str(i+1)+\", A = \"+str(session.run(A))+\", Loss = \"+\n",
    "             str(session.run(xentrop, feed_dict={x_data : rand_x, y_target: rand_y})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
